ğŸŒ Access the Web Pages
1. Frontend Dashboard (React UI)

http://localhost:3000
This is the main vulnerability scanner dashboard where you can:

Upload/scan Docker images
View scan results
See vulnerability statistics
Opened Simple Browser at http://localhost:3000

2. Backend API (FastAPI)

http://localhost:8000
3. API Documentation (Swagger UI)

http://localhost:8000/docs
Interactive API documentation where you can test endpoints directly.

Opened Simple Browser at http://localhost:8000/docs

ğŸ”§ Kubernetes Access (if using K8s)
For the Kubernetes deployment, use port-forwarding:


#Â APIÂ (alreadyÂ forwardedÂ toÂ 8080)kubectlÂ port-forwardÂ -nÂ vulnscanÂ svc/vulnscan-apiÂ 8080:80#Â AccessÂ at:Â http://localhost:8080#Â ArgoCDÂ UIkubectlÂ port-forwardÂ svc/argocd-serverÂ -nÂ argocdÂ 9090:443#Â AccessÂ at:Â https://localhost:9090#Â Login:Â adminÂ /Â Xx0tZblpNib4CBK8
ğŸ“‹ Quick Summary
Service	URL	Description
Frontend	http://localhost:3000	React Dashboard
API	http://localhost:8000	FastAPI Backend
API Docs	http://localhost:8000/docs	Swagger UI
Health Check	http://localhost:8000/health	API Health
K8s API	http://localhost:8080	(via port-forward)
ArgoCD	https://localhost:9090	(via port-forward)

--------------------------------------------------------------------------

âœ… Summary: All Phases Complete!
Here's a quick reference of all the commands executed:

ğŸ“‹ PHASE 1: Run Locally (Without Kubernetes)
Step 1.1: Run PostgreSQL

dockerÂ runÂ -dÂ \Â Â --nameÂ vulnscan-dbÂ \Â Â -eÂ POSTGRES_USER=userÂ \Â Â -eÂ POSTGRES_PASSWORD=passwordÂ \Â Â -eÂ POSTGRES_DB=vulnscanÂ \Â Â -pÂ 5432:5432Â \Â Â postgres:15-alpine
Explanation: Starts PostgreSQL 15 with credentials matching docker-compose.yml

Step 1.2: Apply Migration

dockerÂ cpÂ migrations/001_initial_schema.sqlÂ vulnscan-db:/tmp/dockerÂ execÂ vulnscan-dbÂ psqlÂ -UÂ userÂ -dÂ vulnscanÂ -fÂ /tmp/001_initial_schema.sql
Explanation: Creates tables, indexes, triggers, and views for vulnerability scan data

Step 1.3: Create .env and Run Backend

catÂ >Â .envÂ <<Â 'EOF'DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/vulnscanENVIRONMENT=development...EOFsourceÂ venv/bin/activateuvicornÂ app.main:appÂ --hostÂ 0.0.0.0Â --portÂ 8000Â --reload
Explanation: Starts FastAPI on http://localhost:8000 with hot-reload

Step 1.4: Run Worker

sourceÂ venv/bin/activatepythonÂ -mÂ app.worker
Explanation: Runs Trivy scanner worker as a Python module (respects package imports)

Step 1.5: Run Frontend

cdÂ frontendnpmÂ installnpmÂ runÂ dev
Explanation: Starts Vite dev server on http://localhost:3000

ğŸ“‹ PHASE 2: Build Docker Images

#Â BuildÂ backendÂ (APIÂ +Â WorkerÂ useÂ sameÂ image)dockerÂ buildÂ -fÂ Dockerfile.backendÂ -tÂ vulnscan-backend:latestÂ .#Â BuildÂ frontenddockerÂ buildÂ -fÂ Dockerfile.frontendÂ -tÂ vulnscan-frontend:latestÂ .#Â TagÂ forÂ K8sdockerÂ tagÂ vulnscan-backend:latestÂ vulnscan-api:latestdockerÂ tagÂ vulnscan-backend:latestÂ vulnscan-worker:latest
Note: Worker and API share the same image. Worker runs python -m app.worker, API runs uvicorn.

ğŸ“‹ PHASE 3: Run on Kubernetes (KinD)
Step 3.1: Create KinD Cluster

catÂ <<EOFÂ |Â kindÂ createÂ clusterÂ --nameÂ vulnscanÂ --config=-kind:Â ClusterapiVersion:Â kind.x-k8s.io/v1alpha4nodes:Â Â -Â role:Â control-planeÂ Â Â Â extraPortMappings:Â Â Â Â Â Â -Â containerPort:Â 30080Â Â Â Â Â Â Â Â hostPort:Â 30080Â Â Â Â Â Â Â Â protocol:Â TCPEOF
Step 3.2: Load Images

kindÂ loadÂ docker-imageÂ vulnscan-api:latestÂ --nameÂ vulnscankindÂ loadÂ docker-imageÂ vulnscan-worker:latestÂ --nameÂ vulnscankindÂ loadÂ docker-imageÂ vulnscan-frontend:latestÂ --nameÂ vulnscan
Step 3.3-3.5: Deploy

kubectlÂ applyÂ -fÂ k8s/namespace.yamlkubectlÂ applyÂ -fÂ k8s/postgres.yaml#Â ApplyÂ migrationkubectlÂ cpÂ migrations/001_initial_schema.sqlÂ vulnscan/postgres-0:/tmp/kubectlÂ execÂ -nÂ vulnscanÂ postgres-0Â --Â psqlÂ -UÂ scannerÂ -dÂ vulnscanÂ -fÂ /tmp/001_initial_schema.sqlkubectlÂ applyÂ -fÂ k8s/api.yamlkubectlÂ applyÂ -fÂ k8s/worker.yaml
Verification

kubectlÂ getÂ podsÂ -nÂ vulnscankubectlÂ port-forwardÂ -nÂ vulnscanÂ svc/vulnscan-apiÂ 8080:80curlÂ http://localhost:8080/health
ğŸ“‹ PHASE 4: GitOps with ArgoCD
Step 4.1: Install ArgoCD

kubectlÂ createÂ namespaceÂ argocdkubectlÂ applyÂ -nÂ argocdÂ -fÂ https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
Step 4.2: Get Admin Password

kubectlÂ -nÂ argocdÂ getÂ secretÂ argocd-initial-admin-secretÂ -oÂ jsonpath="{.data.password}"Â |Â base64Â -d
Admin credentials: admin / Xx0tZblpNib4CBK8

Step 4.3: Apply ArgoCD App

kubectlÂ applyÂ -fÂ k8s/argocd-app.yaml
Access ArgoCD UI

kubectlÂ port-forwardÂ svc/argocd-serverÂ -nÂ argocdÂ 9090:443#Â Open:Â https://localhost:9090
How ArgoCD keeps the app synced:

ArgoCD watches the Git repository specified in argocd-app.yaml
When changes are pushed to the k8s/ directory, ArgoCD detects them
With syncPolicy.automated.selfHeal: true, ArgoCD automatically applies changes
prune: true removes resources deleted from Git
Current Status:

Component	Status
PostgreSQL (K8s)	âœ… Running
API (K8s)	âœ… 2/2 pods running
Worker (K8s)	âœ… Running
ArgoCD	âœ… Installed
ArgoCD App	âœ… Created (needs valid Git URL to sync)
